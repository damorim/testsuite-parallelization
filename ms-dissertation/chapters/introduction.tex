\Comment{
Software maintenance starts as early as the first software artifacts are
delivered, and is characterized by its high cost and slow speed of
implementation~\citetp{swebok2004}. It has been stated that it is the most
expensive activity of software development, taking up to 90\% of the total
costs~\citetp{Eastwood1993,Erlikh2000}. However, despite of the high cost, it is
mandatory to ensure the success of the software project. \citett{Lehman1980}
argues, in his \emph{Continuing Change} law of software evolution, that the
modification of software is a fact of life for software systems if they are
intended to remain useful. \citett{Bennett2000} reinforced such an argument for
the specific case of useful and successful software, where almost all of them
have a common practice of stimulating user-generated \ac{cr}. Actually, software
maintenance is driven by \acp{cr} reported by many stakeholders, such as
developers, testers, team leaders, managers, and clients.

In this context, the \ac{cr} repositories play an important role in the
maintenance and evolution process, being actually a focal point of communication
and coordination for software projects~\citetp{Bertram2010}. Through a \ac{cr}
repository, the developers manage and coordinate the corrections and new
features to be implemented in the software under development or maintenance.
Moreover, the data stored in such repositories are a valuable source of
information about the project, which can be used to assist in cost estimation,
impact analysis, traceability, planning, expertise discovery, and software
understanding \citetp{CavalcantiSQJ2011}. Examples of these repositories are
Mantis~\citetp{Mantis}, Bugzilla~\citetp{Bugzilla}, and Trac~\citetp{Trac}.

Briefly, a \ac{cr} describes a defect to be fixed, an adaptive or perfective
change, or a new functionality to be implemented in a software
system~\citetp{CavalcantiSQJ2011}. Each \ac{cr} stores a variety of fields of
free text and custom fields defined according to the necessity of each project.
In Trac, for example, it has fields for summary and detailed description of a
\ac{cr}. In the same \ac{cr}, it can be also recorded information about software
version, dependencies with other \acp{cr} (such as \acp{cr} that are blocked,
similar, or duplicate), the person who will be assigned to the \ac{cr}, among
other relevant information. Moreover, during the life cycle of a \ac{cr},
different kinds of discussion take place through the comments that are inserted
in it, such as fixing alternatives, workarounds, and architectural
decisions~\citetp{Bertram2010}.

\section[Motivation  (Why to Automate CR Assignment?)]{Motivation (Why to
Automate \ac{cr} Assignment?)}

Despite \ac{cr} repositories claimed benefits to software maintenance and
evolution, handling \acp{cr} is not cost-free. For example, when new \acp{cr}
are reported they must be assigned to developers which have adequate expertise
to address the request~\citetp{Aljarah2011,Hosseini2012,Kagdi2012}. Finding the
appropriate developer is crucial for obtaining the lowest, economically
feasible, fixing time~\citetp{Lucca2002}. Nevertheless, assigning \acp{cr} to
developers is a labor-intensive and time consuming
task~\citetp{Anvik2006,Jeong2009}. Indeed, depending on the project being
developed, the amount of \acp{cr} that are reported and need to be assigned can
vary from dozens to hundreds per day~\citetp{CavalcantiSQJ2011}.

\figref{fig:assignment-schema} shows the activity of assigning \acp{cr}.
At the top-left corner of the figure, there are the \acp{cr} which have been
reported to the software project. At the bottom-left corner, there is a set of
developers which could be assigned to those \acp{cr}. Then, at the center, the
assignment of \acp{cr} is performed; the \acp{cr} and developers must be
matched, and each developer should fix one or more \acp{cr}. Commonly, the
matching is performed aiming at the shortest time and the highest quality for
the \ac{cr} fixing activities.

\begin{figure}[htp]
\centering
  \caption[\ac{cr} assignment.]{\ac{cr} assignment. The router, which may be the
  \acs{ccb}, project leaders, or managers, must match \acp{cr} and developers in
  order to obtain the shortest fixing and highest quality.}
  \includegraphics[width=\columnwidth]{images/assignment-schema.pdf}
  \footnotesize{Source: Made by the author.}
  \label{fig:assignment-schema}
\end{figure}

\lipsum[2-4]

Nevertheless, by increasing the amount of reported \acp{cr} or the size of the
development team, it is visible that the router becomes overloaded and the
\ac{cr} assignment becomes an intensive, error prone activity. It was confirmed
by \citett{Jeong2009}, which identified that 37\%-44\% of the \acp{cr} in Mozilla
and Eclipse projects did not reach the right developer in the first assignment.
These \acp{cr}, in turn, had their fixing time delayed because they needed to be
reassigned one or more times. Furthermore, if the \acp{cr} are not fixed by the
appropriate developers, there is also the chance of introducing new defects
during the \acp{cr} fixing.

In this context, we believe that it is necessary to develop methods and tools to
automate the assignment of \acp{cr} and ensure that the \acp{cr} are being
assigned to the appropriate developers. With these methods and tools, we could
reduce the time needed to perform the assignments and, given that the
appropriate developers are actually being selected, the quality and time for the
\ac{cr} fixing are also improved.

\section{Problem Statement}
\label{sec:intro-problem-statement}

As previously mentioned, software maintenance has been considered as the most
costly aspect of software development~\citetp{swebok2004}. There is a myriad of
reasons for this situation. One of them is the many changes that are required
after software delivery due to poor documented and misunderstood requirements,
or simply because \emph{``the clients do not know what they
want''}~\citetp{Brooks1995}.

Another reason is the fact that a set of development activities must be
inevitably performed in order to implement a change. For instance, for each
change to be implemented it is necessary to comprehend the existing software
artifacts, modify the software's source code to implement the change, perform
tests and verification, and deliver the new version of the software.
Additionally, very often, the implementation of the change ends up by
introducing new defects in the software.
   
A third reason is the management aspects of software maintenance. It is
necessary to keep track of all these changes that are performed, generally
considering different versions of the software and customers.

\lipsum[3-5]

\begin{enumerate}
  \item Firstly, the approaches available in the literature were designed to
  perform autonomously. That is, the software analysts do not have the control
  of the approach; they cannot modify the approach's behavior. Without
  such control, in turn, the approach cannot be properly calibrated. As a
  consequence, if the approach's performance is not satisfactory, it is simply
  discarded.
  \item Secondly, the reported values for accuracy of these approaches are
  still low. With low accuracy, the previous reason takes place. That is, as the
  approaches perform with low accuracy, and the software analysts do not have
  control over them, the approaches are simply discarded.
  \item Finally, the third reason concerns the lack of contextual information in
  those approaches. As is well known, software development companies are
  dynamic: developers move from projects; developers are hired/fired;
  developers enter in vacation or take a day off; and developers have different
  experiences. This dynamic influences the assignment of \acp{cr}. Thus,
  contextual information is a necessity in automated approaches.
\end{enumerate}

Based on this context, the main research question investigated by this thesis is:

\begin{description}
  \item[Research question] \emph{Is it possible to develop a new approach for
  automated \ac{cr} assignment with satisfactory accuracy, leveraging
  contextual information, and designed in order to put the software analysts in
  control of such approach?}
\end{description}

With the objective to answer this question, it is necessary to understand
current approaches available in the literature, choose the correct technologies
that could support dynamic environments and, mainly, understand the necessities
of software analysts regarding a new approach for automated \ac{cr} assignment.
Thus, the goal of the work described in this thesis can be stated as:

\begin{description}
  \item[Research objective] \emph{This work proposes an automated approach for
  \ac{cr} assignment which uses \ac{ir} models, expert systems, and
  context-aware information in order to select the appropriate developers. The
  approach is supported by the state-of-the-art in the management of \acp{cr} as
  well as by the understanding of the aspects concerning the \ac{cr} assignment
  activity itself.}
\end{description} 

\section{Overview of the Proposal}
\lipsum[1-5]

\section{Research Methodology}

This research design of this thesis is based on a multimethod
approach~\citetp{Hesse-Biber2010}. Such approach combines two or more
quantitative (or qualitative) methods in a single study, such as a survey and an
experiment~\citetp{Hesse-Biber2010}. Multimethod must not be confused with mixed
method. In this last, methods for both qualitative and quantitative types of
research are applied in a single study. On the other hand, multimethod studies
combine different methods for a single research type.

When applying a multimethod approach, the triangulation is used to consolidate
the results from the different methods, considering, however, that the same
research question(s) was/were investigated in these methods. As a consequence,
the triangulation of methods enhances the conclusions and completeness of the
study, bringing more credibility to the research
findings~\citetp{Hesse-Biber2010}. \figref{fig:research-methodology-thesis} shows
the multimethod research design applied in this thesis.

\begin{figure}[h]
\centering
  \caption[Research methodology.]{The research methodology applied for this
  thesis.}
  \includegraphics[width=\columnwidth]{images/research-methodology-thesis.pdf}
  \footnotesize{Source: Made by the author.}
  \label{fig:research-methodology-thesis}
\end{figure}

The design started by stating the research objective, which we defined in
\secref{sec:intro-problem-statement}, and performing the initial literature
review. This last provided the basic concepts and understanding of the area.
Then, a systematic mapping study and a questionnaire-based survey were
conducted. These two gathered detailed information on our research topic.
Indeed, both of them were used to understand the key aspects of \ac{cr}
assignment and identify the set of requirements to automate the assignments. In
the evidence synthesis step, these results were detailed and organized in order
to formulate the approach to automate \ac{cr} assignments, which was constructed
in the next step. Finally, the research design states the validation of the
proposed approach.

\section{Out of Scope}

As the proposed approach is part of a broader context, a set of related aspects
will be left out of its scope. Thus, the following topics are not directly
addressed in this thesis:

\begin{enumerate}
  \item \textbf{Tools for \ac{cr} management.} We are addressing
  a specific aspect of \ac{cr} management, which is the \ac{cr} assignment
  activity. Thus, it is out of scope of this thesis to provide a
  complete solution for \ac{cr} management. Instead, we are planning to
  implement standalone software which will be able to integrate with the
  most well known tools for \ac{cr} management, such as Mantis, Bugzilla, and
  Trac, providing a service to leverage the automation of \ac{cr}
  assignments.
  
  \item \textbf{Software maintenance process.} Software maintenance involves
  a set of activities aiming at implementing modifications in some software
  project. These activities must be coordinated through a process so that the
  maintenance can be successful. In Chapter 2, we discuss some of
  these processes. However, in this thesis, we are not concerned with the
  maintenance process itself. Actually, it should be transparent in our approach
  to automate \ac{cr} assignment. Thus, it is out of scope of this
  thesis to provide any process assessment for software maintenance beyond the
  activity of \ac{cr} assignment.
  
  \item \textbf{\ac{ir} models.} Many models for \ac{ir} have been proposed for
  different objectives, including the \ac{cr} assignment itself. However, due to
  the broad availability of these models, it is out of scope of this thesis to
  develop a new one. Instead, the \ac{ir} models with better performance,
  identified through the systematic mapping study, were chose to be
  integrated in our approach;
  
  \item \textbf{Rule-based expert systems.} Similar to \ac{ir} models,
  rule-based expert systems have a long history of development. Thus, our
  approach does not intend to develop a whole new system with this purpose.
  Actually, we integrated in our approach the
  Drools\footnote{\url{http://www.jboss.org/drools/}} expert system, which is a
  mature tool that can be easily manipulated;
  
  \item \textbf{Mathematical formulations on NP-Complete problems.} We
  understand that the problem of assigning \acp{cr} to software developers is in
  the broad category of \emph{assignment problems}, which is well known to be
  NP-Complete. Thus, could be formulated as such. However, the mathematical
  formulations of the \ac{cr} assignment problem is out of scope of this thesis.
  As well as finding an optimal solution on the context of NP-Complete problems
  is also out of scope. The main reason for this is the human factors and
  context variables that are involved in the assignment of \acp{cr}, which
  make this problem hard to be computable. A mathematical formulation of the
  \ac{cr} assignment problem is provided by~\citett{Rahman2009}.
\end{enumerate}

\section{Statement of the Contributions}
\lipsum[6-7]

\begin{enumerate}
  \item An overview of the software maintenance concepts and processes, with
  emphasis on the importance of \ac{cr} management aspects; 
  \item A survey performed with practitioners from a large organization, in
  order to understand the aspects of the \ac{cr} assignment
  activity. Published in the \emph{17$^{th}$ International Conference on Evaluation
  and Assessment in Software Engineering (EASE'2013)}~\citetp{CavalcantiEASE2013};
  \item A replication of the previous survey in two more organizations;
  \item A systematic mapping study performed to understand the challenges and
  opportunities of \ac{cr} management, as well as to identify research gaps and
  the road ahead. Accepted for publication in the
  \emph{Journal of Software: Evolution and Process}~\citetp{CavalcantiJSEP2013};
  \item The definition of the functional and non-functional requirements that
  are required to effectively automate \ac{cr} assignment, which takes as input
  the systematic mapping study and the survey;
  \item The definition of an approach that satisfies the
  identified requirements to automate the \ac{cr} assignment activity;
  \item The realization of the proposed approach's architecture, in which we
  described the methods and techniques used for the implementation, as well as the
  components that have to be built and the third party components that should be
  assembled together in order to provide a service for automated \ac{cr}
  assignment; and
  \item The evaluation of the proposed approach, performed as an offline
  experiment simulating a real context.
\end{enumerate}

\section{Organization of the Thesis}

\lipsum[5-10]
}

\chapter{Introduction}
\label{chp:intro}

% \begin{quotation}[]{Poul Anderson}
% I have yet to see any problem, however complicated, which, when looked at in the
% right way, did not become still more complicated.
% \end{quotation}

Dealing with high testing costs has been an important problem in
software engineering research and industrial practice.  Several
approaches have been proposed in the research literature to address
this problem, with the focus mainly on test suite minimization,
prioritization, reduction, and selection~\cite{yoo-harman-stvr2012}.
In industry, the focus has been mainly on distributing the testing
workload.  Evidence of this are the Google TAP
system~\citet{google-tap,google-ci} and the Microsoft CloudBuild
system~\citet{prasad-shulte-ieee-microsoft-ci}, which provide
distributed infrastructures to efficiently build massive amounts of
code and run tests.  Building in-house server clusters is also a
popular mechanism to distribute testing workloads.  For example, as of
August 2013, the test suite of the Groupon PWA system, which powers
the \url{groupon.com} website, included over 19K tests.  To run all
those tests under 10m, Groupon used a cluster of 4 computers with 24
cores each~\citet{kim-etal-fse2013}.

At large organizations, the alternative of renting cloud
services~\citet{cloud-services} or even building proprietary
infrastructures for running tests is a legitimate approach to mitigate
the regression testing problem.  However, for projects with modest
 or nonexistent budgets and yet relatively heavy testing workloads, this solution may
not be economically viable.  For these cases, the use of commodity
hardware\Comment{ (\eg{}, existing workstations)} is an attractive
solution for running tests.  The proliferation of
multi-core CPUs and the increasing popularization of testing
frameworks and build systems, which today provide mature support for
parallelization, enable\Comment{ test execution} speedups through increased CPU
usage~(see Section~\ref{sec:modes}).  These two elements~---~demand
for cost-effective test execution and supply of relatively inexpensive
testing infrastructures~---~inspired us to investigate 
test suite parallelization in practice.

This paper reports on an empirical study we conducted to analyze the
usage and impact of low-level parallelization to speed up testing in
open-source projects.  This is a relevant problem given the tremendous
popularity of open-source development and regression testing
research~\citet{yoo-harman-stvr2012}.  Note that parallelization is
complementary to other approaches to mitigate testing costs such as
(safe) test
selection~\citet{Rothermel:1997:SER:248233.248262,gligoric-etal-issta2015}
and continuous integration~\citet{Saff:2003:RWD:951952.952340}.

The dimensions of analysis we considered in this study are (i)
feasibility, (ii) adoption, (iii) speedup, and (iv) tradeoffs.  The
dimension \emph{feasibility} measures the potential of parallelization
to reduce testing costs.  In the limit, parallelization would be
fruitless if all projects had short-running test suites or if the
execution cost was dominated by a single test case in the suite.  The
dimension \emph{adoption} evaluates how often existing open-source
projects use parallelization schemes and how developers involved in
costly projects (not using test suite parallelization) perceive this
technology.  It is important to measure resistance of practitioners to
the technology and to understand their reasons.  The dimension
\emph{speedup} evaluates the observed impact of
parallelization\Comment{~---~when used in selected open-source
  projects~---~} in running times.  Finally, the dimension
\emph{tradeoffs} evaluates the relationship between speedups obtained
with parallelization and issues that arise 
when running tests in parallel, including test
flakiness~\citet{luo-etal-fse2014,bell-etal-esecfse2015}.  We briefly summarize our findings
in the following.


\noindent\emph{Feasibility.}~To assess how prevalent long-running test suites
are we selected \numSubjs{} popular Java projects from \github{} containing
Maven build files~\citet{maven}.  Section~\ref{sec:eval} details our methodology
to select subjects and to isolate our experiments from environmental noise.
Results indicate that nearly \percentMedLongRunning{} of the projects take at
least 1m to run and \percentLongRunning{} of the projects take at least 5m to
run.  Considering the \numMedLong{} projects with test suites taking longer than
a minute to run, the average execution time of a test suite was
\averageMedLongRunning{}.  Results also show that test cases are typically
short-running, typically taking less than half a second to run.  Furthermore, we
found that only in rare cases few test cases monopolize the overall time to run
a test suite.


\noindent\emph{Adoption.}~ We considered two aspects in measuring technology
adoption.  First, we measured usage of parallelism in open-source projects.
Then, we ran a survey with developers to understand the reasons that could
explain resistance to using the technology.\Comment{ For the quantitative
analysis we checked both statically (parsing build files) and dynamically
(monitoring execution of build files) for the presence of parallelization.}
Considering only the projects whose test suites take longer than a minute to
run, we found that only \percentParallelUpdated{} of them use parallelism.  We
also contacted developers from a selection of costly projects that did not use
parallelization to understand the reasons for not using parallelization.
Dealing with concurrency-related issues (\eg{}, the extra work to organize test
suite to avoid concurrency errors) and the availability of continuous
integration services were the most frequently answered reasons for not
considering parallelization.

\noindent\emph{Speedups.}~We used two setups to measure speedups.  In one setup
we measured speedups obtained on projects that run test suites in parallel by
default.  In the other setup, we evaluated how execution scales with the number
of available cores in the machine.\Comment{We did not change parallel
configurations on that setup.  For comparison, we disabled parallel execution to
obtain the running time of a sequential execution.}  Considering the first
setup, results indicate that the average speedup of parallelization was
\avgSpeedup{}x.  Although we found cases with very high speedups (\eg{}, 28.8x
for project Jcabi), we also found cases where the speedups were not very
significant.  Considering the scalability experiment, we noticed, perhaps as
expected, that parallelization obtained with forking JVMs scales with the number
of cores but the speedups are bounded by long-running test classes.

\noindent\emph{Tradeoffs.}~Test flakiness is a central concern when running
tests in parallel.  Dependent tests can be affected by different schedulings of
test methods and classes.  This dimension of the study measures the impact of
different parallel configurations on test flakiness and speedup.  Overall,
results indicate that configurations that fork JVMs do not achieve speedups as
high as other more-aggressive configurations, but they manifest much lower
flakiness ratios.

Our observations may trigger different actions:

%\setlist[itemize]{leftmargin=1.1em}
\begin{itemize}
\item \emph{Incentivize forking.}~Forked JVMs manifest very low rates
  of test flakiness.  Developers of projects with long-running test
  suites should consider using that feature, which is available in
  modern build systems today (\eg{}, Maven).
\item \emph{Break test dependencies.}~Non-forked JVMs can achieve
  impressive speedups at the expense of sometimes impressive rates of
  flakiness.  Breaking test dependencies (with
  ElectricTest~\citet{bell-etal-esecfse2015}, for example) to avoid flakiness is advised for developers with
  greater interest in efficiency.
\item \emph{Refactor tests for load balancing.}~The configuration with
  forked JVMs scales
  better\Comment{ with the number of cores} when the test workload is balanced
  across testing classes.  Automated refactoring could help balance
  the workload in scenarios where developers are not willing to change
  test code but have access to machines with a high number of cores.
\item \emph{Improve debugging for build systems.}~While preparing our
  experiments, we found scenarios\Comment{, related to test
    parallelization,} where Maven's executions did not reflect
  corresponding JUnit's executions.\Comment{(Docker reproduction scripts
  available.)} Those issues can hinder developers from using parallel
  testing. Better debugging support for build systems could help
  on that. 
\end{itemize}

The artifacts we produced as result of this study are available from
the following web page \webpage{}.

