% Computer Society journal (but not conference!) papers do something unusual
% with the very first section heading (almost always called "Introduction").
% They place it ABOVE the main text! IEEEtran.cls does not automatically do
% this for you, but you can achieve this effect with the provided
% \IEEEraisesectionheading{} command. Note the need to keep any \label that
% is to refer to the section immediately after \section in the above as
% \IEEEraisesectionheading puts \section within a raised box.
\IEEEraisesectionheading{\section{Introduction}\label{sec:intro}}

% The very first letter is a 2 line initial drop letter followed
% by the rest of the first word in caps (small caps for compsoc).
% 
% form to use if the first word consists of a single letter:
% \IEEEPARstart{A}{demo} file is ....
% 
% form to use if you need the single drop letter followed by
% normal text (unknown if ever used by the IEEE):
% \IEEEPARstart{A}{}demo file is ....
% 
% Some journals put the first two words in caps:
% \IEEEPARstart{T}{his demo} file is ....
% 
% Here we have the typical use of a "D" for an initial drop letter
% and "EALING" in caps to complete the first word.
\IEEEPARstart{D}{ealing} with high testing costs has been an important problem in
software engineering research and industrial practice.  Several
approaches have been proposed in the research literature to address
this problem, with the focus mainly on test suite minimization,
prioritization, reduction, and selection~\cite{yoo-harman-stvr2012}.
In industry, the focus has been mainly on distributing the testing
workload.  Evidence of this are the Google TAP
system~\cite{google-tap,google-ci} and the Microsoft CloudBuild
system~\cite{prasad-shulte-ieee-microsoft-ci}, which provide
distributed infrastructures to efficiently build massive amounts of
code and run tests.  Building in-house server clusters is also a
popular mechanism to distribute testing workloads.  For example, as of
August 2013, the test suite of the Groupon PWA system, which powers
the \url{groupon.com} website, included over 19K tests.  To run all
those tests under 10m, Groupon used a cluster of 4 computers with 24
cores each~\cite{kim-etal-fse2013}.

At large organizations, the alternative of renting cloud
services~\cite{cloud-services} or even building proprietary
infrastructures for running tests is a legitimate approach to mitigate
the regression testing problem.  However, for projects with modest
 or nonexistent budgets and yet relatively heavy testing workloads, this solution may
not be economically viable.  For these cases, the use of commodity
hardware\Comment{ (\eg{}, existing workstations)} is an attractive
solution for running tests.  The proliferation of
multi-core CPUs and the increasing popularization of testing
frameworks and build systems, which today provide mature support for
parallelization, enable\Comment{ test execution} speedups through increased CPU
usage~(see Section~\ref{sec:modes}).  These two elements~---~demand
for cost-effective test execution and supply of relatively inexpensive
testing infrastructures~---~inspired us to investigate 
test suite parallelization in practice.

This paper reports on an empirical study we conducted to analyze the
usage and impact of low-level parallelization to speed up testing in
open-source projects.  This is a relevant problem given the tremendous
popularity of open-source development and regression testing
research~\cite{yoo-harman-stvr2012}.  Note that parallelization is
complementary to other approaches to mitigate testing costs such as
(safe) test
selection~\cite{Rothermel:1997:SER:248233.248262,gligoric-etal-issta2015}
and continuous integration~\cite{Saff:2003:RWD:951952.952340}.

The dimensions of analysis we considered in this study are (i)
feasibility, (ii) adoption, (iii) speedup, and (iv) tradeoffs.  The
dimension \emph{feasibility} measures the potential of parallelization
to reduce testing costs.  In the limit, parallelization would be
fruitless if all projects had short-running test suites or if the
execution cost was dominated by a single test case in the suite.  The
dimension \emph{adoption} evaluates how often existing open-source
projects use parallelization schemes and how developers involved in
costly projects (not using test suite parallelization) perceive this
technology.  It is important to measure resistance of practitioners to
the technology and to understand their reasons.  The dimension
\emph{speedup} evaluates the observed impact of
parallelization\Comment{~---~when used in selected open-source
  projects~---~} in running times.  Finally, the dimension
\emph{tradeoffs} evaluates the relationship between speedups obtained
with parallelization and issues that arise 
when running tests in parallel, including test
flakiness~\cite{luo-etal-fse2014,bell-etal-esecfse2015}.  We briefly summarize our findings
in the following.


\noindent\emph{Feasibility.}~To assess how prevalent long-running test suites
are we selected \numSubjs{} popular Java projects from \github{} containing
Maven build files~\cite{maven}.  Section~\ref{sec:eval} details our methodology
to select subjects and to isolate our experiments from environmental noise.
Results indicate that nearly \percentMedLongRunning{} of the projects take at
least 1m to run and \percentLongRunning{} of the projects take at least 5m to
run.  Considering the \numMedLong{} projects with test suites taking longer than
a minute to run, the average execution time of a test suite was
\averageMedLongRunning{}.  Results also show that test cases are typically
short-running, typically taking less than half a second to run.  Furthermore, we
found that only in rare cases few test cases monopolize the overall time to run
a test suite.


\noindent\emph{Adoption.}~ We considered two aspects in measuring technology
adoption.  First, we measured usage of parallelism in open-source projects.
Then, we ran a survey with developers to understand the reasons that could
explain resistance to using the technology.\Comment{ For the quantitative
analysis we checked both statically (parsing build files) and dynamically
(monitoring execution of build files) for the presence of parallelization.}
Considering only the projects whose test suites take longer than a minute to
run, we found that only \percentParallelUpdated{} of them use parallelism.  We
also contacted developers from a selection of costly projects that did not use
parallelization to understand the reasons for not using parallelization.
Dealing with concurrency-related issues (\eg{}, the extra work to organize test
suite to avoid concurrency errors) and the availability of continuous
integration services were the most frequently answered reasons for not
considering parallelization.

\noindent\emph{Speedups.}~We used two setups to measure speedups.  In one setup
we measured speedups obtained on projects that run test suites in parallel by
default.  In the other setup, we evaluated how execution scales with the number
of available cores in the machine.\Comment{We did not change parallel
configurations on that setup.  For comparison, we disabled parallel execution to
obtain the running time of a sequential execution.}  Considering the first
setup, results indicate that the average speedup of parallelization was
\avgSpeedup{}x.  Although we found cases with very high speedups (\eg{}, 28.8x
for project Jcabi), we also found cases where the speedups were not very
significant.  Considering the scalability experiment, we noticed, perhaps as
expected, that parallelization obtained with forking JVMs scales with the number
of cores but the speedups are bounded by long-running test classes.

\noindent\emph{Tradeoffs.}~Test flakiness is a central concern when running
tests in parallel.  Dependent tests can be affected by different schedulings of
test methods and classes.  This dimension of the study measures the impact of
different parallel configurations on test flakiness and speedup.  Overall,
results indicate that configurations that fork JVMs do not achieve speedups as
high as other more-aggressive configurations, but they manifest much lower
flakiness ratios.

Our observations may trigger different actions:

%\setlist[itemize]{leftmargin=1.1em}
\begin{itemize}
\item \emph{Incentivize forking.}~Forked JVMs manifest very low rates
  of test flakiness.  Developers of projects with long-running test
  suites should consider using that feature, which is available in
  modern build systems today (\eg{}, Maven).
\item \emph{Break test dependencies.}~Non-forked JVMs can achieve
  impressive speedups at the expense of sometimes impressive rates of
  flakiness.  Breaking test dependencies (with
  ElectricTest~\cite{bell-etal-esecfse2015}, for example) to avoid flakiness is advised for developers with
  greater interest in efficiency.
\item \emph{Refactor tests for load balancing.}~The configuration with
  forked JVMs scales
  better\Comment{ with the number of cores} when the test workload is balanced
  across testing classes.  Automated refactoring could help balance
  the workload in scenarios where developers are not willing to change
  test code but have access to machines with a high number of cores.
\item \emph{Improve debugging for build systems.}~While preparing our
  experiments, we found scenarios\Comment{, related to test
    parallelization,} where Maven's executions did not reflect
  corresponding JUnit's executions.\Comment{(Docker reproduction scripts
  available.)} Those issues can hinder developers from using parallel
  testing. Better debugging support for build systems could help
  on that. 
\end{itemize}

The artifacts we produced as result of this study are available from
the following web page \webpage{}.

%% \Mar{missing connection. why parallelism?}  From these results we
%% investigated (2) how frequently the projects we considered use
%% parallelization to speedup test runs.  Our results indicate that
%% \percentParallelForLongRunning{} of long-running test suites do use
%% parallelism to speedup execution.  Given the popularity of this
%% solution, we further studied: (3) what are the causes of high
%% execution cost in individual tests (CPU vs. IO) and (4) how uniformly
%% cost is distributed across tests.  These questions help to assess the
%% impact of parallelization in test suite execution.  Intuitively,
%% IO-intensive test suites and test suites with uneven distribution of
%% cost per test are factors that limit the benefits of parallelization.
%% Results indicate that \Fix{...}  Finally, we investigated (5) what are
%% the limitations related to parallelization that could justify adoption
%% resistance.

%% To illustrate the importance of parallel test execution, \Jbc{TODO -
%% Write a paragraph motivating this paper.}

%% This paper reports an empirical study to evaluate the impact of
%% parallelization options on test execution speedup \Fix{...}\Jbc{TODO -
%% Summary of the contributions of this paper} .

%%  LocalWords:  parallelization multicore JUnit TestNG NUnit XXm YYm
%%  LocalWords:  Groupon parallelizing multi JVMs CPUs JVM Milos TODO
%%  LocalWords:  Ekstazi github CloudBuild PWA groupon criticality VM

 	
%%% Local Variables:
%%% TeX-master: "main"
%%% End:
%%  LocalWords:  jenkins API VMs datarace tradeoffs tradeoff Paretto
%%  LocalWords:  schedulings posteriori priori bla blabla Jcabi
%%  LocalWords:  scalability parallelize Incentivize Refactor JUnit's
%%  LocalWords:  refactoring
